{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现流程：\n",
    "\n",
    "#### 1. 读取原始数据集（文本集）\n",
    "\n",
    "#### 2. 文本预处理\n",
    "* **2.1 清理无用的标点符号**\n",
    "* **2.2 根据 换行符 \\n 分割**\n",
    "* **2.3 单词 --> 索引 转换**\n",
    "* **2.4 标签 --> 1， 0 转换**\n",
    "* **2.5 清理文本太短以及过长的样本**\n",
    "* **2.6 将单词映射为整型**\n",
    "* **2.7 设定统一的文本长度，对整个文本数据中的每条评论进行填充或截断**\n",
    "\n",
    "#### 3. 特征工程\n",
    "* **3.1 array --> tensor**\n",
    "* **3.2 将数据集分离成：train, val, test 三部分，比例是： 0.8, 0.1, 0.1**\n",
    "* **3.3 通过DataLoader按批处理数据**\n",
    "\n",
    "#### 4. 定义网络模型结构\n",
    "\n",
    "#### 5. 定义超参数\n",
    "\n",
    "#### 6. 定义训练函数（训练 + 验证）\n",
    "\n",
    "#### 7. 定义测试函数\n",
    "\n",
    "#### 8. 定义预测函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:31:40.660203Z",
     "start_time": "2025-04-15T04:31:40.656203Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 加载文本和标签数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:31:57.561274Z",
     "start_time": "2025-04-15T04:31:57.435632Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取文本数据\n",
    "with open(\"reviews.txt\", 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:31:59.036034Z",
     "start_time": "2025-04-15T04:31:59.029381Z"
    }
   },
   "outputs": [],
   "source": [
    "len(text) # 共33678267个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:00.333881Z",
     "start_time": "2025-04-15T04:32:00.328288Z"
    }
   },
   "outputs": [],
   "source": [
    "type(text) # 类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:01.794463Z",
     "start_time": "2025-04-15T04:32:01.790055Z"
    }
   },
   "outputs": [],
   "source": [
    "text[:10] # 显示前10个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:05.736437Z",
     "start_time": "2025-04-15T04:32:05.730983Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取标签数据\n",
    "with open('labels.txt', 'r') as file:\n",
    "    labels = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:07.200706Z",
     "start_time": "2025-04-15T04:32:07.195680Z"
    }
   },
   "outputs": [],
   "source": [
    "len(labels) # 共225000个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels) # 类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:10] # 显示前10个字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 数据 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:10.386156Z",
     "start_time": "2025-04-15T04:32:10.381168Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1 清理无用的标点符号\n",
    "from string import punctuation\n",
    "\n",
    "print(\"标点符号 : \", punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:16.164148Z",
     "start_time": "2025-04-15T04:32:12.733155Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_text = ''.join([char for char in text if char not in punctuation]) # 遍历文本中每一个字符，跳过标点符合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_text) # 新的文本字符个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:18.123970Z",
     "start_time": "2025-04-15T04:32:18.093794Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.2 根据 换行符 \\n 分割\n",
    "clean_text = clean_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:19.441542Z",
     "start_time": "2025-04-15T04:32:19.436988Z"
    }
   },
   "outputs": [],
   "source": [
    "len(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:23.753933Z",
     "start_time": "2025-04-15T04:32:23.748969Z"
    }
   },
   "outputs": [],
   "source": [
    "# 标签 根据 \\n 分割\n",
    "labels = labels.split('\\n')\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:25.203532Z",
     "start_time": "2025-04-15T04:32:25.199179Z"
    }
   },
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:28.478084Z",
     "start_time": "2025-04-15T04:32:26.730167Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.3 字典： 单词 --> 索引\n",
    "\n",
    "# 获取所有评论中的每个单词\n",
    "words = [word.lower() for sentence in clean_text for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:33.601010Z",
     "start_time": "2025-04-15T04:32:33.597387Z"
    }
   },
   "outputs": [],
   "source": [
    "words[:10] # 显示前10个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:35.782804Z",
     "start_time": "2025-04-15T04:32:35.122814Z"
    }
   },
   "outputs": [],
   "source": [
    "various_words = list(set(words)) # 筛选出所有评论中不同的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:37.253272Z",
     "start_time": "2025-04-15T04:32:37.248700Z"
    }
   },
   "outputs": [],
   "source": [
    "various_words.remove('') # 清理空字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:38.996415Z",
     "start_time": "2025-04-15T04:32:38.990853Z"
    }
   },
   "outputs": [],
   "source": [
    "len(various_words) # 不同的单词个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:41.006478Z",
     "start_time": "2025-04-15T04:32:40.986392Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建字典，格式： 单词 ： 整数\n",
    "\n",
    "int_word = dict(enumerate(various_words, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:43.072057Z",
     "start_time": "2025-04-15T04:32:43.054492Z"
    }
   },
   "outputs": [],
   "source": [
    "int_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:45.141513Z",
     "start_time": "2025-04-15T04:32:45.114510Z"
    }
   },
   "outputs": [],
   "source": [
    "# 字典，格式： 整数 ： 单词\n",
    "word_int = {w:int(i) for i, w in int_word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:46.157634Z",
     "start_time": "2025-04-15T04:32:46.136420Z"
    }
   },
   "outputs": [],
   "source": [
    "word_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:48.780841Z",
     "start_time": "2025-04-15T04:32:48.775761Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.4 标签 --> 1， 0 转换\n",
    "# positive : 1,  negative : 0\n",
    "\n",
    "label_int = np.array([1 if x == 'positive' else 0 for x in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:51.032643Z",
     "start_time": "2025-04-15T04:32:51.028757Z"
    }
   },
   "outputs": [],
   "source": [
    "len(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:52.327042Z",
     "start_time": "2025-04-15T04:32:52.318504Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T04:32:54.618413Z",
     "start_time": "2025-04-15T04:32:53.833182Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.5 清理文本太短以及过长的样本\n",
    "\n",
    "# 统计文本中，每条评论的长度\n",
    "sentence_length = [len(sentence.split()) for sentence in clean_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(sentence_length) # 统计不同长度的评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最小评论长度\n",
    "min_sen = min(sorted(counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大评论长度\n",
    "max_sen = max(sorted(counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 min 和 max 对应的索引\n",
    "\n",
    "min_index = [i for i, length in enumerate(sentence_length) if length == min_sen[0]]\n",
    "\n",
    "max_index = [i for i, length in enumerate(sentence_length) if length == max_sen[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据索引删除文本中过短或过长的评论\n",
    "\n",
    "new_text = np.delete(clean_text, min_index)\n",
    "\n",
    "print(\"原始文本数量： \", len(clean_text))\n",
    "print(\"新文本数量: \", len(new_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text2 = np.delete(new_text, max_index)\n",
    "\n",
    "print(\"原始文本数量： \", len(new_text))\n",
    "print(\"新文本数量: \", len(new_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样需要在标签集中根据索引删除对应的标签\n",
    "\n",
    "new_labels = np.delete(label_int, min_index)\n",
    "\n",
    "new_labels = np.delete(new_labels, max_index)\n",
    "\n",
    "print(\"原始标签数量： \", len(label_int))\n",
    "print(\"新标签数量： \", len(new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 将单词映射为整型\n",
    "\n",
    "text_ints = []\n",
    "for sentence in new_text2:\n",
    "    sample = list()\n",
    "    for word in sentence.split():\n",
    "        int_value = word_int[word] # 获取到单词对应的键\n",
    "        sample.append(int_value)\n",
    "    text_ints.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ints[0] # 第一条评论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_ints) # 总的评论数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 设定统一的文本长度，对整个文本数据中的每条评论进行填充或截断\n",
    "# 设定每条评论固定长度为200个单词，不足的评论用0填充，超过的直接截断\n",
    "\n",
    "def reset_text(text, seq_len):\n",
    "    dataset = np.zeros((len(text), seq_len))\n",
    "    for index, sentence in enumerate(text):\n",
    "        if len(sentence) < seq_len:\n",
    "            dataset[index, :len(sentence)] = sentence\n",
    "        else:\n",
    "            dataset[index, :] = sentence[:seq_len] # 截断\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = reset_text(text_ints, seq_len=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(label_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 3.1 数据类型转换\n",
    "dataset_tensor = torch.from_numpy(dataset)\n",
    "label_tensor = torch.from_numpy(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 数据分割，train, val, test\n",
    "\n",
    "# 总样本数\n",
    "all_samples = len(dataset_tensor)\n",
    "print(\"总样本数：\",all_samples)\n",
    "\n",
    "# 设置比例\n",
    "ratio = 0.8\n",
    "train_size = int(all_samples * 0.8) # 训练样本数\n",
    "print(\"训练样本数：\",train_size)\n",
    "\n",
    "rest_size = all_samples - train_size # 剩余样本数\n",
    "\n",
    "val_size = int(rest_size * 0.5) # 验证样本数\n",
    "print(\"验证样本数：\", val_size)\n",
    "\n",
    "test_size = int(rest_size * 0.5) # 测试样本数\n",
    "print(\"测试样本数：\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取train, val, test 样本\n",
    "\n",
    "# train\n",
    "train = dataset_tensor[:train_size]\n",
    "train_labels = label_tensor[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剩余样本\n",
    "rest_samples = dataset_tensor[train_size:]\n",
    "rest_labels = label_tensor[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "val = rest_samples[:val_size]\n",
    "val_labels = rest_labels[:val_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test = rest_samples[val_size:]\n",
    "test_labels = rest_labels[val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 通过DataLoader按批处理数据\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 对数据进行封装：(评论，标签)\n",
    "train_dataset = TensorDataset(train, train_labels)\n",
    "val_dataset = TensorDataset(val, val_labels)\n",
    "test_dataset = TensorDataset(test, test_labels)\n",
    "\n",
    "batch_size = 128\n",
    "# 批处理\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取train中的一批数据\n",
    "data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 定义网络模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentiment(nn.Module):\n",
    "    def __init__(self, input_size, embedding_dim, hidden_dim, output_size, num_layers, dropout=0.5):\n",
    "        super(sentiment, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, embedding_dim) # 词嵌入层\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        '''\n",
    "        x shape : (batch_size, seq_len, features)\n",
    "        \n",
    "        '''\n",
    "        batch_size = x.size(0) # 获取batch_size\n",
    "        x = x.long() # 类型转换\n",
    "        #print('x shape : ', x.shape) # torch.Size([128, 200])\n",
    "        embeds = self.embedding(x) # 词嵌入表示 \n",
    "        #print('embeds shape : ', embeds.shape) # torch.Size([128, 200, 300])\n",
    "        out, hidden = self.lstm(embeds, hidden) # lstm out shape : (batch_size, seq_len, hidden_dim)\n",
    "        #print('out_1 shape : ', out.shape) # torch.Size([128, 200, 256])\n",
    "        #print('hidden_0 shape : ', hidden[0].shape) # torch.Size([2, 128, 256])\n",
    "        #print('hidden_1 shape : ', hidden[1].shape) # torch.Size([2, 128, 256])\n",
    "        out = out.reshape(-1, self.hidden_dim) # （batch_size * seq_len, hidden_dim）\n",
    "        #print('out_2 shape : ', out.shape) # torch.Size([25600, 256])\n",
    "        out = self.linear(out) # 全连接层 \n",
    "        #print('out_3 shape : ', out.shape) # torch.Size([25600, 1])\n",
    "        sigmoid_out = self.sigmoid(out) #\n",
    "        #print('sigmoid_out_1 shape : ', sigmoid_out.shape) # torch.Size([25600, 1])\n",
    "        sigmoid_out = sigmoid_out.reshape(batch_size, -1)\n",
    "        #print('sigmoid_out_2 shape : ', sigmoid_out.shape) # torch.Size([128, 200])\n",
    "        sigmoid_out = sigmoid_out[:, -1] # 获取最后一批的标签\n",
    "        #print('sigmoid_out_3 shape : ', sigmoid_out.shape) # torch.Size([128])\n",
    "        return sigmoid_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        #print(\"weghit :\", weight.shape) # torch.Size([74073, 300])\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化超参数\n",
    "input_size = len(word_int) + 1 # 输入（不同的单词个数）\n",
    "output_size = 1 # 输出\n",
    "embedding_dim = 400 # 词嵌入维度\n",
    "hidden_dim = 128 # 隐藏层节点个数\n",
    "num_layers = 2 # lstm的层数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = sentiment(input_size, embedding_dim, hidden_dim, output_size, num_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss() # 损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # 优化器\n",
    "num_epochs = 50 # 循环次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练模型\n",
    "def train(model, device, data_loader, criterion, optimizer, num_epochs, val_loader):\n",
    "    history = list()\n",
    "    for epoch in range(num_epochs):\n",
    "        hs = model.init_hidden(batch_size)\n",
    "        train_loss = []\n",
    "        train_correct = 0.0\n",
    "        model.train()\n",
    "        for data, target in data_loader:\n",
    "            data = data.to(device) # 部署到device\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad() # 梯度置零\n",
    "            output, hs = model(data, hs) # 模型训练\n",
    "            hs = tuple([h.data for h in hs])\n",
    "            #print('output shape : ', output.shape) # torch.Size([128])\n",
    "            loss = criterion(output, target.float()) # 计算损失\n",
    "            train_loss.append(loss.item()) # 累计损失\n",
    "            loss.backward() # 反向传播\n",
    "            optimizer.step() # 参数更新\n",
    "            train_correct += torch.sum(output==target) # 比较\n",
    "            \n",
    "        # 模型验证\n",
    "        model.eval()\n",
    "        hs = model.init_hidden(batch_size)\n",
    "        val_loss = []\n",
    "        val_correct = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                preds, hs = model(data, hs) # 验证\n",
    "                hs = tuple([h.data for h in hs])\n",
    "                loss = criterion(preds, target.float()) # 计算损失\n",
    "                val_loss.append(loss.item()) # 累计损失\n",
    "                val_correct += torch.sum(preds==target) # 比较\n",
    "#             history['val_loss'].append(np.mean(val_loss))\n",
    "#             history['val_correct'].append(np.mean(val_correct))\n",
    "#         history['train_loss'].append(np.mean(train_loss))\n",
    "#         history['train_correct'].append(np.mean(train_correct))\n",
    "        print(f'Epoch {epoch}/{num_epochs} --- train loss {np.round(np.mean(train_loss), 5)} --- val loss {np.round(np.mean(val_loss),5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, device, train_loader, criterion, optimizer, num_epochs, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "\n",
    "def test(model, data_loader, device, criterion):\n",
    "    test_losses = []\n",
    "    num_correct = 0\n",
    "    # 初始化隐藏状态\n",
    "    hs = model.init_hidden(batch_size)\n",
    "    model.eval()\n",
    "    for i, dataset in enumerate(data_loader):\n",
    "        data = dataset[0].to(device) # 部署到device\n",
    "        target = dataset[1].to(device)\n",
    "        output, hs = model(data, hs) # 测试\n",
    "        loss = criterion(output, target.float()) # 计算损失\n",
    "        pred = torch.round(output) # 将预测值进行四舍五入，转换为0 或 1\n",
    "        test_losses.append(loss.item()) # 保存损失\n",
    "        correct_tensor = pred.eq(target.float().view_as(pred)) # 返回一堆True 或 False\n",
    "        correct = correct_tensor.cpu().numpy()\n",
    "        result = np.sum(correct)\n",
    "        num_correct += result\n",
    "        #print(\"num correct : \", num_correct)\n",
    "        print(f'Batch {i}')\n",
    "        print(f'loss : {np.round(np.mean(loss.item()), 3)}')\n",
    "        print(f'accuracy : {np.round(result / len(data), 3) * 100} %')\n",
    "        print()\n",
    "    print(\"总的测试损失 test loss : {:.2f}\".format(np.mean(test_losses)))\n",
    "    print(\"总的测试准确率 test accuracy : {:.2f}\".format(np.mean(num_correct / len(data_loader.dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, test_loader, device, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测（测试）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 案例1\n",
    "text = 'this movie is so amazing. the plot is attractive. and I really like it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步：文本转索引（整数）\n",
    "from string import punctuation\n",
    "\n",
    "def converts(text):\n",
    "    # 去除标点符号\n",
    "    new_text = ''.join([char for char in text if char not in punctuation])\n",
    "    print(\"new text :\\n\", new_text)\n",
    "    # 文本映射为索引\n",
    "    text_ints = [word_int[word.lower()] for word in new_text.split()]\n",
    "    print(\"文本映射为索引：\\n\", text_ints)\n",
    "    return text_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ints = converts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本对齐，sequence_length = 200\n",
    "new_text_ints = reset_text([text_ints], seq_len=200) # 注意这里要添加一个[]，因为，reset_text处理的二维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text_ints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy --> tensor\n",
    "text_tensor = torch.from_numpy(new_text_ints)\n",
    "\n",
    "print(text_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义预测函数\n",
    "def predict(model, text_tensor, device):\n",
    "    batch_size = text_tensor.size(0) # 这里是1\n",
    "    hs = model.init_hidden(batch_size) # 初始化隐藏状态\n",
    "    text_tensor = text_tensor.to(device)\n",
    "    pred, hs = model(text_tensor, hs) # 判断\n",
    "    print(\"概率值：\", pred.item())\n",
    "    # 将pred概率值转换为0或1\n",
    "    pred = torch.round(pred)\n",
    "    print(\"类别值：\", pred.item())\n",
    "    # 判断\n",
    "    if pred.data == 1:\n",
    "        print(\"评论正面\")\n",
    "    else:\n",
    "        print(\"评论反面\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, text_tensor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
